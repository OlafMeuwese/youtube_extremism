{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import youtubecollector as ytc\n",
    "import sys\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append videos in one videofile and drop the duplicates in the separate file\n",
    "\n",
    "#output_file = 'output/left/videos_left.csv'\n",
    "#input_files = 'output/left/raw_data/videos_left_*.csv'\n",
    "\n",
    "output_file = 'output/right/videos_right.csv'\n",
    "input_files = 'output/right/raw_data/videos_right_*.csv'\n",
    "\n",
    "column_names = ['video_id',\n",
    "              'video_published',\n",
    "              'channel_id',\n",
    "              'video_title',\n",
    "              'video_description',\n",
    "              'video_channel_title',\n",
    "              'video_tags',\n",
    "              'video_category_id',\n",
    "              'video_default_language',\n",
    "              'video_duration',\n",
    "              'video_view_count',\n",
    "              'video_comment_count',\n",
    "              'video_likes_count',\n",
    "              'video_dislikes_count',\n",
    "              'video_topic_ids',\n",
    "              'video_topic_categories'\n",
    "               ]\n",
    "\n",
    "\n",
    "for filename in glob.glob(input_files):\n",
    "    file = pd.read_csv(filename)\n",
    "    df = file.drop_duplicates()\n",
    "    if not os.path.isfile(output_file):\n",
    "           df.to_csv(output_file, \n",
    "                     mode='a', \n",
    "                     header=column_names,\n",
    "                     sep='¶',\n",
    "                     quotechar='þ',\n",
    "                    )\n",
    "    else: \n",
    "           df.to_csv(output_file, \n",
    "                     mode='a', \n",
    "                     header=False,\n",
    "                     sep='¶',\n",
    "                     quotechar='þ'\n",
    "                    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262963"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the duplicates in the appended file\n",
    "input_file = 'output/right/videos_right.csv'\n",
    "column_names = ['video_id',\n",
    "              'video_published',\n",
    "              'channel_id',\n",
    "              'video_title',\n",
    "              'video_description',\n",
    "              'video_channel_title',\n",
    "              'video_tags',\n",
    "              'video_category_id',\n",
    "              'video_default_language',\n",
    "              'video_duration',\n",
    "              'video_view_count',\n",
    "              'video_comment_count',\n",
    "              'video_likes_count',\n",
    "              'video_dislikes_count',\n",
    "              'video_topic_ids',\n",
    "              'video_topic_categories'\n",
    "               ]\n",
    "videos = pd.read_csv(input_file,\n",
    "                     sep='¶',\n",
    "                     quotechar='þ',\n",
    "                     engine='python',\n",
    "                     index_col=None,\n",
    "                     skiprows=[1]\n",
    "                     )\n",
    "\n",
    "len(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = videos.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_published</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_description</th>\n",
       "      <th>video_channel_title</th>\n",
       "      <th>video_tags</th>\n",
       "      <th>video_category_id</th>\n",
       "      <th>video_default_language</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>video_view_count</th>\n",
       "      <th>video_comment_count</th>\n",
       "      <th>video_likes_count</th>\n",
       "      <th>video_dislikes_count</th>\n",
       "      <th>video_topic_ids</th>\n",
       "      <th>video_topic_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bSx-WpcSvh0</td>\n",
       "      <td>2018-08-08T19:49:03.000Z</td>\n",
       "      <td>UCJIAT4v6irhZChsrB4hzsPA</td>\n",
       "      <td>Trailer for Interview on HPANWO Radio 9 Aug 20...</td>\n",
       "      <td>Programme notes  https://hpanwo-radio.blogspot...</td>\n",
       "      <td>Cosmic Claire</td>\n",
       "      <td>['CS Lewis', 'Out of the Silent Planet', 'Voya...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>not set</td>\n",
       "      <td>PT2M45S</td>\n",
       "      <td>48</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['/m/02jjt', '/m/02jjt']</td>\n",
       "      <td>['https://en.wikipedia.org/wiki/Entertainment']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGKcO-NMLb0</td>\n",
       "      <td>2018-07-21T23:05:12.000Z</td>\n",
       "      <td>UCJIAT4v6irhZChsrB4hzsPA</td>\n",
       "      <td>Claire Rae Randall ~ Waking the Monkey! Interv...</td>\n",
       "      <td>Claire Rae Randall on The Hundredth Monkey Rad...</td>\n",
       "      <td>Cosmic Claire</td>\n",
       "      <td>['Hundredth Monkey', 'Waking the Monkey', 'Cla...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>not set</td>\n",
       "      <td>PT1H58M50S</td>\n",
       "      <td>35</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['/m/02jjt', '/m/02jjt']</td>\n",
       "      <td>['https://en.wikipedia.org/wiki/Entertainment']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mWWjMGYJRGo</td>\n",
       "      <td>2018-07-17T22:36:44.000Z</td>\n",
       "      <td>UCJIAT4v6irhZChsrB4hzsPA</td>\n",
       "      <td>Channel Update ~ The War on Gender</td>\n",
       "      <td>Update on the progress of my forthcoming book ...</td>\n",
       "      <td>Cosmic Claire</td>\n",
       "      <td>['Transgender', 'War on Gender', 'Waking The M...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>not set</td>\n",
       "      <td>PT26M26S</td>\n",
       "      <td>38</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['/m/019_rr', '/m/0kt51', '/m/019_rr', '/m/0kt...</td>\n",
       "      <td>['https://en.wikipedia.org/wiki/Lifestyle_(soc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ssJJAmpv8AY</td>\n",
       "      <td>2018-03-29T02:55:36.000Z</td>\n",
       "      <td>UCJIAT4v6irhZChsrB4hzsPA</td>\n",
       "      <td>False Allegations Made Against Me</td>\n",
       "      <td>Further to the cancellation of my talk 'The Wa...</td>\n",
       "      <td>Cosmic Claire</td>\n",
       "      <td>not set</td>\n",
       "      <td>27.0</td>\n",
       "      <td>not set</td>\n",
       "      <td>PT33M57S</td>\n",
       "      <td>137</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['/m/019_rr', '/m/019_rr']</td>\n",
       "      <td>['https://en.wikipedia.org/wiki/Lifestyle_(soc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JgmPirHGe9Q</td>\n",
       "      <td>2018-03-28T22:29:46.000Z</td>\n",
       "      <td>UCJIAT4v6irhZChsrB4hzsPA</td>\n",
       "      <td>Someone Doesn't Like Me</td>\n",
       "      <td>Following the cancellation of my pre-launch ev...</td>\n",
       "      <td>Cosmic Claire</td>\n",
       "      <td>['Transgender', 'Transsexual', 'War on Gender'...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>not set</td>\n",
       "      <td>PT4M22S</td>\n",
       "      <td>134</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>not set</td>\n",
       "      <td>not set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id           video_published                channel_id  \\\n",
       "0  bSx-WpcSvh0  2018-08-08T19:49:03.000Z  UCJIAT4v6irhZChsrB4hzsPA   \n",
       "1  SGKcO-NMLb0  2018-07-21T23:05:12.000Z  UCJIAT4v6irhZChsrB4hzsPA   \n",
       "2  mWWjMGYJRGo  2018-07-17T22:36:44.000Z  UCJIAT4v6irhZChsrB4hzsPA   \n",
       "3  ssJJAmpv8AY  2018-03-29T02:55:36.000Z  UCJIAT4v6irhZChsrB4hzsPA   \n",
       "4  JgmPirHGe9Q  2018-03-28T22:29:46.000Z  UCJIAT4v6irhZChsrB4hzsPA   \n",
       "\n",
       "                                         video_title  \\\n",
       "0  Trailer for Interview on HPANWO Radio 9 Aug 20...   \n",
       "1  Claire Rae Randall ~ Waking the Monkey! Interv...   \n",
       "2                 Channel Update ~ The War on Gender   \n",
       "3                  False Allegations Made Against Me   \n",
       "4                            Someone Doesn't Like Me   \n",
       "\n",
       "                                   video_description video_channel_title  \\\n",
       "0  Programme notes  https://hpanwo-radio.blogspot...       Cosmic Claire   \n",
       "1  Claire Rae Randall on The Hundredth Monkey Rad...       Cosmic Claire   \n",
       "2  Update on the progress of my forthcoming book ...       Cosmic Claire   \n",
       "3  Further to the cancellation of my talk 'The Wa...       Cosmic Claire   \n",
       "4  Following the cancellation of my pre-launch ev...       Cosmic Claire   \n",
       "\n",
       "                                          video_tags  video_category_id  \\\n",
       "0  ['CS Lewis', 'Out of the Silent Planet', 'Voya...               27.0   \n",
       "1  ['Hundredth Monkey', 'Waking the Monkey', 'Cla...               27.0   \n",
       "2  ['Transgender', 'War on Gender', 'Waking The M...               27.0   \n",
       "3                                            not set               27.0   \n",
       "4  ['Transgender', 'Transsexual', 'War on Gender'...               27.0   \n",
       "\n",
       "  video_default_language video_duration video_view_count  video_comment_count  \\\n",
       "0                not set        PT2M45S               48                  8.0   \n",
       "1                not set     PT1H58M50S               35                  2.0   \n",
       "2                not set       PT26M26S               38                  7.0   \n",
       "3                not set       PT33M57S              137                 11.0   \n",
       "4                not set        PT4M22S              134                  9.0   \n",
       "\n",
       "   video_likes_count  video_dislikes_count  \\\n",
       "0                4.0                   1.0   \n",
       "1                2.0                   0.0   \n",
       "2                4.0                   0.0   \n",
       "3                6.0                   1.0   \n",
       "4               10.0                   0.0   \n",
       "\n",
       "                                     video_topic_ids  \\\n",
       "0                           ['/m/02jjt', '/m/02jjt']   \n",
       "1                           ['/m/02jjt', '/m/02jjt']   \n",
       "2  ['/m/019_rr', '/m/0kt51', '/m/019_rr', '/m/0kt...   \n",
       "3                         ['/m/019_rr', '/m/019_rr']   \n",
       "4                                            not set   \n",
       "\n",
       "                              video_topic_categories  \n",
       "0    ['https://en.wikipedia.org/wiki/Entertainment']  \n",
       "1    ['https://en.wikipedia.org/wiki/Entertainment']  \n",
       "2  ['https://en.wikipedia.org/wiki/Lifestyle_(soc...  \n",
       "3  ['https://en.wikipedia.org/wiki/Lifestyle_(soc...  \n",
       "4                                            not set  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos.to_csv(output_file,\n",
    "                header=column_names,\n",
    "                sep='¶',\n",
    "                quotechar='þ',\n",
    "                index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the comment files into one file and drop duplicates while we are at it.\n",
    "\n",
    "#output_file = 'output/right/comments_right.csv'\n",
    "#input_files = 'output/right/raw_data/comments_right_*.csv'\n",
    "\n",
    "output_file = 'output/left/comments_left.csv'\n",
    "input_files = 'output/left/raw_data/comments_left_*.csv'\n",
    "\n",
    "column_names = ['video_id',\n",
    "              'comment_id',\n",
    "              'author_display_name',\n",
    "              'author_channel_url',\n",
    "              'author_channel_id',\n",
    "              'comment_text',\n",
    "              'comment_like_count',\n",
    "              'comment_dislike_count',\n",
    "              'comment_time',\n",
    "              'reply_count']\n",
    "\n",
    "\n",
    "\n",
    "for filename in glob.glob(input_files):\n",
    "    for chunk in pd.read_csv(filename, chunksize=2000000, names=column_names):\n",
    "        df = chunk.drop_duplicates()\n",
    "        if not os.path.isfile(output_file):\n",
    "               df.to_csv(output_file, \n",
    "                         mode='a', \n",
    "                         header=column_names,\n",
    "                         sep='¶',\n",
    "                         quotechar='þ'\n",
    "                        )\n",
    "        else: \n",
    "               df.to_csv(output_file, \n",
    "                         mode='a', \n",
    "                         sep='¶',\n",
    "                         quotechar='þ',\n",
    "                         header=False \n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output/right/recommendations_right.csv'\n",
    "input_files = 'output/right/raw_data/recommendations_right_*.csv'\n",
    "\n",
    "#output_file = 'output/left/recommendations_left.csv'\n",
    "#input_files = 'output/left/raw_data/recommendations_left_*.csv'\n",
    "\n",
    "\n",
    "column_names = ['source_video_id',\n",
    "                'target_video_id',\n",
    "                'published_at', \n",
    "                'channel_id',\n",
    "                'video_title',\n",
    "                'video_description']\n",
    "\n",
    "\n",
    "for filename in glob.glob(input_files):\n",
    "    for chunk in pd.read_csv(filename, chunksize=2000000):\n",
    "        df = chunk.drop_duplicates()\n",
    "        if not os.path.isfile(output_file):\n",
    "               df.to_csv(output_file, \n",
    "                         mode='a', \n",
    "                         header=column_names,\n",
    "                         sep='¶',\n",
    "                         quotechar='þ'\n",
    "                        )\n",
    "        else: \n",
    "               df.to_csv(output_file, \n",
    "                         mode='a', \n",
    "                         sep='¶',\n",
    "                         quotechar='þ',\n",
    "                         header=False \n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = pd.read_csv(output_file, \n",
    "                    low_memory=False,\n",
    "                    sep='¶',\n",
    "                    quotechar='þ',\n",
    "                    names=column_names\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = recs.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output/right/transcripts_right.csv'\n",
    "input_files = 'output/right/raw_data/transcripts_right/*.vtt'\n",
    "\n",
    "#output_file = 'output/left/transcripts_left.csv'\n",
    "#input_files = 'output/left/raw_data/transcripts_left/*.vtt'\n",
    "\n",
    "\n",
    "for filename in glob.glob(input_files):\n",
    "    video_id_transcripts = ytc.transcripts.extract_transcripts(filename)\n",
    "    ytc.transcripts.write_transcripts(output_file, video_id_transcripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move rows from left to right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "right = pd.read_csv('output/right/channels_right.csv')\n",
    "left = pd.read_csv('output/left/channels_left.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_to_remove = [ 'John B. Wells The ONLY Official CTM Channel', \n",
    "                            'Epimetheus',\n",
    "                            'Safiya Nygaard',\n",
    "                            'Echo Gillette',\n",
    "                            'VanDeGraph',\n",
    "                            'Press For Truth',\n",
    "                            'AtheismTV',\n",
    "                            'Shädbase',\n",
    "                            'Binary Rose',\n",
    "                            'Brotcrunsher',\n",
    "                            'Arzamas',\n",
    "                            'VisualPolitik EN',\n",
    "                            'Maffick',\n",
    "                            'The Natural Farmer',\n",
    "                            'Freedom in Thought',\n",
    "                            'GabrielleBernstein',\n",
    "                            'Gregory B. Sadler',\n",
    "                            'Gray Winsler',\n",
    "                            'The Financial Diet',\n",
    "                            'Invisible People',\n",
    "                            'Jack Buckingham',\n",
    "                            'John Beckley',\n",
    "                            'Inštitut za delavske študije',\n",
    "                            'Infrarouge',\n",
    "                            'Johnny Ringo',\n",
    "                            'SWIM',\n",
    "                            'blndsundoll4mj',\n",
    "                            'Ingrid Nilsen',\n",
    "                            'Kendall Rae',\n",
    "                            'JaclynGlenn',\n",
    "                            'The Dollar Vigilante',\n",
    "                            'AMTV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_to_move = ['Drunken Peasants', \"Ken O'Keefe\", 'Kraut',\n",
    "           'Project Veritas Action', 'Aydin Paladin', 'Ben Swann',\n",
    "            'Jesse Lee Peterson', 'The Official Hagmann Report',\n",
    "            'Jonathan Pie', 'JFG Livestreams','Jack Buckby',\n",
    "            'Thunderf00t', 'SotomayorTV2', '1on1 with Tommy Sotomayor',\n",
    "            'The Liberty Hound','Hunter Avallone', 'Undoomed',\n",
    "            'Lionel Nation', 'The Still Report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_new = pd.DataFrame()\n",
    "\n",
    "for channel in channels_to_remove:\n",
    "\n",
    "    cond = left.channel_title == channel\n",
    "    rows = left.loc[cond, :]\n",
    "    left.drop(rows.index, inplace=True)\n",
    "    left_new.append(left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chans_left = left[~left['channel_title'].isin(channels_to_remove)]\n",
    "left.to_csv('output/left/channels_left.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chans_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in channels_to_move:\n",
    "\n",
    "    cond = right.channel_title == channel\n",
    "    rows = right.loc[cond, :]\n",
    "    right = right.append(rows, ignore_index=True)\n",
    "    left.drop(rows.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right.to_csv('output/right/channels_right.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['video_id',\n",
    "              'video_published',\n",
    "              'channel_id',\n",
    "              'video_title',\n",
    "              'video_description',\n",
    "              'video_channel_title',\n",
    "              'video_tags',\n",
    "              'video_category_id',\n",
    "              'video_default_language',\n",
    "              'video_duration',\n",
    "              'video_view_count',\n",
    "              'video_comment_count',\n",
    "              'video_likes_count',\n",
    "              'video_dislikes_count',\n",
    "              'video_topic_ids',\n",
    "              'video_topic_categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids_left = pd.read_csv('output/left/videos_left.csv', \n",
    "                        names=column_names,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        engine='python'\n",
    "                       )\n",
    "len(vids_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids_left.video_channel_title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids_right = pd.read_csv('output/right/videos_right.csv',\n",
    "                        names=column_names,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        engine='python')\n",
    "len(vids_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids_right.video_channel_title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_to_move = []\n",
    "\n",
    "for channel in channels_to_move:\n",
    "    cond = vids_left.video_channel_title == channel\n",
    "    rows_to_move = vids_left.loc[cond, :]\n",
    "    rows = vids_left[cond]\n",
    "    vids_right = vids_right.append(rows_to_move, ignore_index=True, sort=False)\n",
    "    for row in rows_to_move['video_id']:\n",
    "        videos_to_move.append(row)\n",
    "vids_left = vids_left[~vids_left['video_channel_title'].isin(channels_to_move)]\n",
    "vids_left.to_csv('output/left/videos_left.csv',\n",
    "                header=column_names,\n",
    "                sep='¶',\n",
    "                quotechar='þ'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids_right.to_csv('output/right/videos_right.csv',\n",
    "                    header=column_names,\n",
    "                    sep='¶',\n",
    "                    quotechar='þ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtm = pd.DataFrame(videos_to_move)\n",
    "vtm.to_csv('output/left/videos_to_move.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16290"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_to_move = []\n",
    "\n",
    "vtm = pd.read_csv('output/left/videos_to_move.csv')\n",
    "for video in vtm['0']:\n",
    "    videos_to_move.append(video)\n",
    "    \n",
    "len(videos_to_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_to_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids_left.video_channel_title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_to_remove = []\n",
    "\n",
    "for channel in channels_to_remove:\n",
    "    cond = vids_left.video_channel_title == channel\n",
    "    rows_to_remove = vids_left.loc[cond, :]\n",
    "    for row in rows_to_remove['video_id']:\n",
    "        videos_to_remove.append(row)\n",
    "vids_left = vids_left[~vids_left['video_channel_title'].isin(channels_to_remove)]\n",
    "vids_left.to_csv('output/left/videos_left.csv',\n",
    "                header=column_names,\n",
    "                sep='¶',\n",
    "                quotechar='þ')\n",
    "vids_left.video_channel_title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(videos_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtr = pd.DataFrame(videos_to_remove)\n",
    "vtr.to_csv('output/left/videos_to_remove.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13361"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_to_remove = []\n",
    "vtr = pd.read_csv('output/left/videos_to_remove.csv')\n",
    "for video in vtr['0']:\n",
    "    videos_to_remove.append(video)\n",
    "    \n",
    "len(videos_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now do comments, transcripts and recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_to_move = set(videos_to_move)\n",
    "videos_to_remove = set(videos_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['video_id',\n",
    "      'comment_id',\n",
    "      'author_display_name',\n",
    "      'author_channel_url',\n",
    "      'author_channel_id',\n",
    "      'comment_text',\n",
    "      'comment_like_count',\n",
    "      'comment_dislike_count',\n",
    "      'comment_time',\n",
    "      'reply_count']\n",
    "\n",
    "for chunk in pd.read_csv('output/left/comments_left.csv',\n",
    "                        chunksize=1000000, \n",
    "                        names=column_names,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        engine='python'):\n",
    "    \n",
    "    # select chunk with videos we wnt to move\n",
    "    \n",
    "    to_move = chunk[chunk['video_id'].isin(videos_to_move)]\n",
    "    \n",
    "    #write them to a new file\n",
    "    \n",
    "    if not os.path.isfile('output/right/left_comments_for_right.csv'):\n",
    "        to_move.to_csv('output/right/left_comments_for_right.csv', \n",
    "                        mode='a', \n",
    "                        header=column_names,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        index=False)\n",
    "    else: \n",
    "        to_move.to_csv('output/right/left_comments_for_right.csv', \n",
    "                        mode='a', \n",
    "                        header=False,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        index=False)\n",
    "    \n",
    "    # select chunk without videos we don't want\n",
    "    to_keep = chunk[~chunk['video_id'].isin(videos_to_remove)]\n",
    "    \n",
    "    # and write them to a new file\n",
    "    if not os.path.isfile('output/left/clean_comments_left.csv'):\n",
    "        to_keep.to_csv('output/left/clean_comments_left.csv', \n",
    "                        mode='a', \n",
    "                        header=column_names,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        index=False)\n",
    "    else: \n",
    "        to_keep.to_csv('output/left/clean_comments_left.csv', \n",
    "                        mode='a', \n",
    "                        header=False,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['source_video_id',\n",
    "                'target_video_id',\n",
    "                'target_video_published',\n",
    "                'target_channel_id',\n",
    "                'target_video_title']\n",
    "\n",
    "for chunk in pd.read_csv('output/left/recommendations_left.csv',\n",
    "                        chunksize=1000000, \n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        engine='python',\n",
    "                        names=column_names):\n",
    "    \n",
    "    # select chunk with videos we wnt to move\n",
    "    \n",
    "    to_move = chunk.loc[chunk['source_video_id'].isin(videos_to_move), :]\n",
    "    \n",
    "    #write them to a new file\n",
    "    \n",
    "    if not os.path.isfile('output/right/left_recs_for_right.csv'):\n",
    "        to_move.to_csv('output/right/left_recs_for_right.csv', \n",
    "                        mode='a', \n",
    "                        header=column_names,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        index=False)\n",
    "    else: \n",
    "        to_move.to_csv('output/right/left_recs_for_right.csv', \n",
    "                        mode='a', \n",
    "                        header=False,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        index=False)\n",
    "    # remove files that were moved\n",
    "    \n",
    "    # select chunk without videos we don't want\n",
    "    to_keep = chunk.loc[~chunk['source_video_id'].isin(videos_to_remove), :]\n",
    "    \n",
    "    \n",
    "    # and write them to a new file\n",
    "    if not os.path.isfile('output/left/clean_recommendations_left.csv'):\n",
    "        to_keep.to_csv('output/left/clean_recommendations_left.csv', \n",
    "                        mode='a', \n",
    "                        header=column_names,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        index=False)\n",
    "        to_keep.to_csv('output/left/clean_recommendations_left.csv', \n",
    "                        mode='a', \n",
    "                        header=False,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['video_id',\n",
    "               'video_text']\n",
    "\n",
    "for chunk in pd.read_csv('output/left/transcripts_left.csv',\n",
    "                        chunksize=10000, \n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        engine='python',\n",
    "                        names=column_names):\n",
    "    \n",
    "    # select chunk with videos we wnt to move\n",
    "    \n",
    "    to_move = chunk.loc[chunk['video_id'].isin(videos_to_move), :]\n",
    "    \n",
    "    #write them to a new file\n",
    "    \n",
    "    if not os.path.isfile('output/right/left_transcripts_for_right.csv'):\n",
    "        to_move.to_csv('output/right/left_transcripts_for_right.csv', \n",
    "                        mode='a', \n",
    "                        header=column_names,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        index=False)\n",
    "    else: \n",
    "        to_move.to_csv('output/right/left_transcripts_for_right.csv', \n",
    "                        mode='a', \n",
    "                        header=False,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        index=False)\n",
    "        \n",
    "    # remove files that were moved\n",
    "    \n",
    "    # select chunk without videos we don't want\n",
    "    to_keep = chunk.loc[~chunk['video_id'].isin(videos_to_remove), :]\n",
    "    \n",
    "    # and write them to a new file\n",
    "    if not os.path.isfile('output/left/clean_transcripts.csv'):\n",
    "        to_keep.to_csv('output/left/clean_transcripts.csv', \n",
    "                        mode='a', \n",
    "                        header=column_names,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        index=False)\n",
    "    else: \n",
    "        to_keep.to_csv('output/left/clean_transcripts.csv', \n",
    "                        mode='a', \n",
    "                        header=False,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge some files:\n",
    "    \n",
    "1. comments_right - left_comments_for_right\n",
    "2. recommendations_right - left_recs_for_right\n",
    "3. transcripts_right - left_transcripts_for_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using dask\n",
    "\n",
    "column_names = ['video_id',\n",
    "      'comment_id',\n",
    "      'author_display_name',\n",
    "      'author_channel_url',\n",
    "      'author_channel_id',\n",
    "      'comment_text',\n",
    "      'comment_like_count',\n",
    "      'comment_dislike_count',\n",
    "      'comment_time',\n",
    "      'reply_count']\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Read in the csv files.\n",
    "df1 = dd.read_csv('output/right/comments_right.csv',\n",
    "                    names=column_names,\n",
    "                    error_bad_lines=False, \n",
    "                    sep='¶',\n",
    "                    quotechar='þ',\n",
    "                    engine='python')\n",
    "                  \n",
    "df2 = dd.read_csv('output/right/left_comments_for_right.csv', \n",
    "                    names=column_names,\n",
    "                    error_bad_lines=False, \n",
    "                    sep='¶',\n",
    "                    quotechar='þ',\n",
    "                    engine='python')\n",
    "\n",
    "# Merge the csv files.\n",
    "df = dd.concat([df1, df2]).drop_duplicates()\n",
    "\n",
    "# Write the output.\n",
    "df.to_csv('comments_right_final.csv', \n",
    "            mode='a',\n",
    "            header=column_names,\n",
    "            sep='¶',\n",
    "            quotechar='þ',\n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['video_id',\n",
    "      'comment_id',\n",
    "      'author_display_name',\n",
    "      'author_channel_url',\n",
    "      'author_channel_id',\n",
    "      'comment_text',\n",
    "      'comment_like_count',\n",
    "      'comment_dislike_count',\n",
    "      'comment_time',\n",
    "      'reply_count']\n",
    "\n",
    "\n",
    "\n",
    "for chunk in pd.read_csv('output/right/left_comments_for_right.csv',\n",
    "                        chunksize=1000000, \n",
    "                        names=column_names,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        engine='python'):\n",
    "    \n",
    "    if not os.path.isfile('output/right/comments_right.csv'):\n",
    "        chunk.to_csv('output/right/comments_right.csv', \n",
    "                        mode='a', \n",
    "                        header=column_names,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        index=False)\n",
    "    else: \n",
    "        chunk.to_csv('output/right/comments_right.csv', \n",
    "                        mode='a', \n",
    "                        header=False,\n",
    "                        sep='¶',\n",
    "                        quotechar='þ',\n",
    "                        index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "correspondent",
   "language": "python",
   "name": "correspondent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
